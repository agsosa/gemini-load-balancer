# Gemini Load Balancer

A modern NextJS application that serves as a proxy server for the Google Gemini API, with key management, load balancing, and a beautiful UI. This application allows you to efficiently manage multiple Gemini API keys, automatically rotate between them to avoid rate limits, and monitor your API usage with detailed statistics.

![Gemini Load Balancer](https://via.placeholder.com/800x400?text=Gemini+Load+Balancer)

## Features

- **API Key Management**: Add, remove, and monitor your Gemini API keys
- **Load Balancing**: Automatically rotate between multiple API keys to avoid rate limits
- **Usage Statistics**: Monitor your API usage with detailed charts and metrics
- **Logs Viewer**: View and search through request, error, and key event logs
- **API Playground**: Test the Gemini API directly from the UI
- **Dark/Light Mode**: Toggle between dark and light themes
- **Single Command Execution**: Run both frontend and backend with a single command

## Installation

Make sure you have Node.js and Bun installed. Then, clone the repository and install the dependencies:

```bash
# Clone the repository
git clone https://github.com/yourusername/gemini-load-balancer.git
cd gemini-load-balancer

# Install dependencies
bun install
```

## Configuration

The application requires minimal configuration:

1. Create a `.env` file in the project root (or copy from `.env.example`)
2. Set only the PORT number (default is 4269). Example `.env` file:
```
PORT=4269
```

Note: API keys and other settings are managed through the UI and stored in the data folder.

## Running the Application

To start the development server:

```bash
bun run dev
```

The application will be available at http://localhost:4269

For production deployment:

```bash
# Build the application
bun run build

# Start the production server
bun run start
```

## Using as an API Service

To use this load balancer as an API service for your applications:

1. Start the application and access the UI at http://localhost:4269
2. Go to the "API Keys" section and add your Gemini API keys through the UI
3. In your client application, configure the following:
   - Base URL: `http://localhost:4269` (or your deployed URL)
   - API Key: Can be any string (the load balancer ignores this and uses its managed keys)
   - Model: Will be automatically populated from the available Gemini models

Example configuration in your client:
```javascript
const configuration = {
  baseURL: "http://localhost:4269",
  apiKey: "any-string-works", // This is ignored by the load balancer
  model: "gemini-pro" // Available models are shown in the dropdown
};
```

The load balancer will:
1. Receive your requests
2. Use its managed pool of API keys
3. Automatically rotate between keys to avoid rate limits
4. Return the Gemini API response to your application

## API Endpoints

The Gemini Load Balancer provides several API endpoints:

### Gemini API Proxy Endpoints

- **POST `/api/v1/chat/completions`**: Proxy for Gemini chat completions API
  - Supports all parameters from the original Gemini API
  - Handles streaming responses
  - Automatically rotates API keys

- **GET `/api/v1/models`**: Proxy for Gemini models API
  - Returns available models from Gemini

### Management API Endpoints

- **GET `/api/admin/keys`**: Get all API keys
- **POST `/api/admin/keys`**: Add a new API key
- **DELETE `/api/admin/keys/:id`**: Delete an API key

[Rest of the sections remain unchanged...]